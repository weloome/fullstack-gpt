{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebc6c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hello\\nAI: Hi there!'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(reutrn_messages=True)\n",
    "\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi there!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchian.chains import LLMChain\n",
    "\n",
    "llm = ChatOllama(model=\"mistral:latest\", temperature=0.1)\n",
    "\n",
    "memory - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec62f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hello'),\n",
       "  AIMessage(content='Hi there!'),\n",
       "  HumanMessage(content='How are you?'),\n",
       "  AIMessage(content=\"I'm doing well, thanks!\")]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=2, return_messages=Talse)\n",
    "def add_message(input, output): \n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "add_message(\"Hello\", \"Hi there!\")\n",
    "add_message(\"How are you?\", \"I'm doing well, thanks!\")\n",
    "add_message(\"What about you?\", \"I'm great, thanks for asking!\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7541da12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    \n",
      "    Human: 집에 가고싶다\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 네, 당신은 집으로 가고 싶습니다. 차를 타고 가시겠어요? (You want to go home. Shall we go by car?)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"mistral:latest\", temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm, \n",
    "    max_token_limit=80,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"집에 가고싶다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5608bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    System:  The human expresses a desire to go home. The AI suggests they could go by car.\n",
      "    Human: 커피 마시고 싶어\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" It sounds like you'd like to have a cup of coffee first. After that, we can discuss the best way for you to get home. Would you prefer to drive yourself or would you like me to help you find a nearby coffee shop and suggest a route to your home afterwards?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"커피 마시고 싶어\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8333465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "    System:  The human expresses a desire to go home and also mentions wanting coffee. The AI still suggests they could go by car, but the focus has shifted towards the human's additional request for coffee.\n",
      "AI:  It sounds like you'd like to have a cup of coffee first. After that, we can discuss the best way for you to get home. Would you prefer to drive yourself or would you like me to help you find a nearby coffee shop and suggest a route to your home afterwards?\n",
      "    Human: 내 이름은?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" My apologies for not asking your name earlier. It's nice to meet you! Your name is [Name], correct? Now that we know each other a bit better, let me help you find a nearby coffee shop. After enjoying your coffee, I can suggest a route to take you home. Would you prefer a specific type of coffee or any particular chain?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"내 이름은?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
